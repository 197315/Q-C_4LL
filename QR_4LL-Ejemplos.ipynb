{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR_4LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> __Author:__ Marcelo Gabriel Gonzalez\n",
    "<br> __Email:__ marcelo.g.gonzalez95@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae6d2c2-aced-42d5-86c7-c0451d74f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"G:\\Mi unidad\\DATA\\PySpark\\QR_4LL\\Q-C_4LL\\QR_4LL-Classes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('bank-full.csv',sep=\",\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed8d109-da87-41bb-9bd3-3bb51b8e5db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " age       | 58         \n",
      " job       | management \n",
      " marital   | married    \n",
      " education | tertiary   \n",
      " default   | no         \n",
      " balance   | 2143       \n",
      " housing   | yes        \n",
      " loan      | no         \n",
      " contact   | unknown    \n",
      " day       | 5          \n",
      " month     | may        \n",
      " duration  | 261        \n",
      " campaign  | 1          \n",
      " pdays     | -1         \n",
      " previous  | 0          \n",
      " poutcome  | unknown    \n",
      " Target    | no         \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1,vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = R_1_2(df, \"job\")\n",
    "a.compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution in for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age : 100.0\n",
      "job : 100.0\n",
      "marital : 100.0\n",
      "education : 100.0\n",
      "default : 100.0\n",
      "balance : 100.0\n",
      "housing : 100.0\n",
      "loan : 100.0\n",
      "contact : 100.0\n",
      "day : 100.0\n",
      "month : 100.0\n",
      "duration : 100.0\n",
      "campaign : 100.0\n",
      "pdays : 100.0\n",
      "previous : 100.0\n",
      "poutcome : 100.0\n",
      "Target : 100.0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i, ':', R_1_2(df, i).compliance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing multiple rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "\n",
    "R_1_1(df, \"job\", \"str\").save(lista)\n",
    "R_1_2(df, \"job\").save(lista)\n",
    "R_1_3_C(df, \"balance\", \"<\", 0).save(lista)\n",
    "R_1_4(df, \"balance\", 0, 99999).save(lista)\n",
    "#R_1_5(df, \"housing\", [\"yes\",\"no\"]).save(lista)\n",
    "#R_1_6(df,'marital').save(lista)\n",
    "#R_1_7(df, \"age\").save(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Field': 'job',\n",
       "  'Secondary_Field': None,\n",
       "  'Object': 'df',\n",
       "  'Rule_Type': '1.1',\n",
       "  'Population': 1,\n",
       "  'Errors': 1,\n",
       "  'Compliance': 0.0},\n",
       " {'Field': 'job',\n",
       "  'Secondary_Field': None,\n",
       "  'Object': 'df',\n",
       "  'Rule_Type': '1.2',\n",
       "  'Population': 45211,\n",
       "  'Errors': 0,\n",
       "  'Compliance': 100.0},\n",
       " {'Field': 'balance',\n",
       "  'Secondary_Field': None,\n",
       "  'Object': 'df',\n",
       "  'Rule_Type': '1.3_C',\n",
       "  'Population': 45211,\n",
       "  'Errors': 3766,\n",
       "  'Compliance': 91.67},\n",
       " {'Field': 'balance',\n",
       "  'Secondary_Field': None,\n",
       "  'Object': 'df',\n",
       "  'Rule_Type': '1.4',\n",
       "  'Population': 45211,\n",
       "  'Errors': 3767,\n",
       "  'Compliance': 91.67}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o413.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 287.0 failed 1 times, most recent failure: Lost task 0.0 in stage 287.0 (TID 219) (DESKTOP-FVI9KPC executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 29 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 29 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mg:\\Mi unidad\\DATA\\PySpark\\QR_4LL\\Q-C_4LL\\QR_4LL-Ejemplos.ipynb Cell 15\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Mi%20unidad/DATA/PySpark/QR_4LL/Q-C_4LL/QR_4LL-Ejemplos.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results_df \u001b[39m=\u001b[39m finish_report(lista)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Mi%20unidad/DATA/PySpark/QR_4LL/Q-C_4LL/QR_4LL-Ejemplos.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results_df\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a bool\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(truncate, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m truncate:\n\u001b[1;32m--> 606\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mshowString(n, \u001b[39m20\u001b[39;49m, vertical))\n\u001b[0;32m    607\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o413.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 287.0 failed 1 times, most recent failure: Lost task 0.0 in stage 287.0 (TID 219) (DESKTOP-FVI9KPC executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 29 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 29 more\r\n"
     ]
    }
   ],
   "source": [
    "results_df = finish_report(lista)\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o171.javaToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 150.0 failed 1 times, most recent failure: Lost task 0.0 in stage 150.0 (TID 100) (DESKTOP-FVI9KPC executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 31 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 31 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mg:\\Mi unidad\\DATA\\PySpark\\QR_4LL\\Q-C_4LL\\QR_4LL-Ejemplos.ipynb Cell 16\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Mi%20unidad/DATA/PySpark/QR_4LL/Q-C_4LL/QR_4LL-Ejemplos.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_report(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12808\\1836926352.py:5\u001b[0m, in \u001b[0;36mplot_report\u001b[1;34m(reporte_df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_report\u001b[39m(reporte_df: pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m      3\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m8\u001b[39m), facecolor\u001b[39m=\u001b[39m(\u001b[39m.94\u001b[39m, \u001b[39m.94\u001b[39m, \u001b[39m.94\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m     reglas \u001b[39m=\u001b[39m reporte_df\u001b[39m.\u001b[39;49mselect(\u001b[39m'\u001b[39;49m\u001b[39mID_order\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mrdd\u001b[39m.\u001b[39mflatMap(\u001b[39mlambda\u001b[39;00m x:x)\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m      6\u001b[0m     cumplimiento \u001b[39m=\u001b[39m reporte_df\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mCompliance\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mrdd\u001b[39m.\u001b[39mflatMap(\u001b[39mlambda\u001b[39;00m x:x)\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m      8\u001b[0m     cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m<\u001b[39m \u001b[39m90\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m>\u001b[39m \u001b[39m90\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39myellow\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m cumplimiento]\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:175\u001b[0m, in \u001b[0;36mDataFrame.rdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m\"\"\"Returns the content as an :class:`pyspark.RDD` of :class:`Row`.\"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     jrdd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mjavaToPython()\n\u001b[0;32m    176\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd \u001b[39m=\u001b[39m RDD(\n\u001b[0;32m    177\u001b[0m         jrdd, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession\u001b[39m.\u001b[39m_sc, BatchedSerializer(CPickleSerializer())\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\Gabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o171.javaToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 150.0 failed 1 times, most recent failure: Lost task 0.0 in stage 150.0 (TID 100) (DESKTOP-FVI9KPC executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 31 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:164)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:189)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 31 more\r\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_report(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compliance(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
